*** Begin Patch
*** Update File: explore/app/__init__.py
@@
-from flask import Flask
-from pathlib import Path
-import logging
-from logging.handlers import RotatingFileHandler
-import orjson
-from .services.analytics_service import AnalyticsService
-import os
-from flask import request
-from dotenv import load_dotenv, dotenv_values 
-from flask_oauthlib.client import OAuth
-from .services.index import IndexManager
-from .services.search import SearchService
+from flask import Flask
+from pathlib import Path
+import logging
+from logging.handlers import RotatingFileHandler
+import orjson
+from .services.analytics_service import AnalyticsService
+import os
+import threading
+import atexit
+from flask import request
+from dotenv import load_dotenv, dotenv_values 
+from flask_oauthlib.client import OAuth
+from .services.index import IndexManager
+from .services.search import SearchService
@@
-load_dotenv() 
+load_dotenv() 
+
+
+class DuplicateLogFilter(logging.Filter):
+    """Filter that suppresses consecutive duplicate log records and reports counts."""
+
+    def __init__(self, notice_threshold: int = 100):
+        super().__init__()
+        self._notice_threshold = max(1, notice_threshold)
+        self._lock = threading.RLock()
+        self._last_key = None
+        self._last_record = None
+        self._duplicate_count = 0
+
+    def filter(self, record: logging.LogRecord) -> bool:
+        if getattr(record, "_duplicate_notice", False):
+            return True
+
+        notice_payload = None
+        allow_record = True
+
+        message_key = (record.name, record.levelno, record.getMessage())
+
+        with self._lock:
+            if self._last_key is None:
+                self._last_key = message_key
+                self._last_record = record
+                self._duplicate_count = 0
+            elif message_key == self._last_key:
+                self._duplicate_count += 1
+                allow_record = False
+                if self._duplicate_count >= self._notice_threshold:
+                    notice_payload = (self._last_record, self._notice_threshold)
+                    self._duplicate_count = 0
+            else:
+                if self._duplicate_count:
+                    notice_payload = (self._last_record, self._duplicate_count)
+                self._last_key = message_key
+                self._last_record = record
+                self._duplicate_count = 0
+
+        if notice_payload:
+            self._emit_notice(*notice_payload)
+
+        return allow_record
+
+    def flush_pending(self):
+        notice_payload = None
+        with self._lock:
+            if self._duplicate_count and self._last_record:
+                notice_payload = (self._last_record, self._duplicate_count)
+                self._duplicate_count = 0
+                self._last_key = None
+                self._last_record = None
+
+        if notice_payload:
+            self._emit_notice(*notice_payload)
+
+    def _emit_notice(self, record: logging.LogRecord, count: int) -> None:
+        logging.getLogger(record.name).log(
+            record.levelno,
+            "[DUPLICATE] Suppressed %d duplicates of: %s",
+            (count, record.getMessage()),
+            extra={"_duplicate_notice": True},
+        )
+
+
+def _compute_duplicate_threshold(default: int = 100) -> int:
+    raw = os.environ.get("LOG_DUPLICATE_NOTICE_EVERY")
+    if not raw:
+        return default
+    try:
+        value = int(raw)
+        if value < 1:
+            raise ValueError
+        return value
+    except ValueError:
+        logging.getLogger(__name__).warning(
+            "Ignoring invalid LOG_DUPLICATE_NOTICE_EVERY=%r; using default %d",
+            raw,
+            default,
+        )
+        return default
+
+
+_duplicate_log_filter = DuplicateLogFilter(notice_threshold=_compute_duplicate_threshold())
+atexit.register(_duplicate_log_filter.flush_pending)
*** End Patch
