### Bugs Causing Whitespaces to Disappear in the UI After Save - In explore\app\routes\transcripts.py

These bugs primarily arise from inconsistent whitespace handling between the `text` field (full transcript string) and the `words` list (tokenized words with metadata). The code allows saves where `text` has extra/leading/trailing/multiple whitespaces, but `words` does not reflect them accurately. If the UI renders the transcript by joining words from the `/words` endpoint (e.g., inserting spaces between non-`\n` tokens), extra whitespaces collapse or disappear after reload. This is exacerbated by skipping pure whitespace tokens (e.g., `{'word': ' '}`) in the normalized DB storage, making them invisible to `/words`.

| Bug Description | Code References | Why It Causes Whitespace Loss | Reproduction Steps | Severity |
| --- | --- | --- | --- | --- |
| **Skipping pure whitespace tokens during DB population** | `_populate_transcript_words`: `if word.strip() == '': continue` | Pure whitespace tokens (e.g., ' ', '  ') are not inserted into `transcript_words`. The `/words` endpoint prefers querying this table, so reloaded `words` exclude them entirely. Metadata for these tokens is also lost (see below). If the UI joins words with single spaces, multiple spaces become single; if it concatenates directly, all extra spaces vanish. Confirmed via code execution tool: whitespace tokens were skipped in DB insert. | Save with `words` including `{'word': '  '}`; call `/words`—token is gone. | High (direct loss after save) |
| **Whitespace-ignoring comparison allows mismatched `text` and `words`** | `_ensure_words_match_text`: `''.join((ws or '').split()) == ''.join((text or '').split())` | The check collapses all whitespaces (via `.split()`), so `text` with extra spaces (e.g., "hello  world") "matches" `words` without them (e.g., [{'word': 'hello'}, {'word': 'world'}]). Save proceeds without retokenizing, but reloaded `words` lack whitespace tokens, causing UI to render collapsed spaces. Confirmed via code execution: Test2 and Test4 showed no retokenization despite extra spaces in `text`. | Save `text="hello  world"`, `words=[{'word': 'hello'}, {'word': 'world'}]`; reload via `/words`—UI sees "hello world". | High (silent inconsistency) |
| **Retokenization discards whitespaces entirely** | `_tokenize_text_to_words`: `parts = [p for p in line.split() if p]` (uses `str.split()` which collapses whitespaces) | If mismatch triggers retokenization, it rebuilds `words` without any whitespace tokens (pure or leading/trailing). Extra spaces in `text` (e.g., leading " hello" or multiple "hello  world") become single implied spaces in UI rendering. For Hebrew (as in example JSON), leading spaces in words (e.g., " נדב") are lost if retokenized. | Force mismatch (e.g., alter `text` slightly); save and reload—whitespaces gone. | Medium (only if mismatch) |
| **Whitespace tokens ignored in alignment transcript** | `_build_new_window`: `' '.join(t for _, t, _ in new_window if t and (not str(t).isspace()))` | When building `new_transcript` for the aligner, it skips whitespace tokens and joins with single spaces. Alignment won't account for pauses/extra spaces, potentially misaligning subsequent tokens. On save, updated timings may overwrite without preserving whitespace positions. | Save with whitespace tokens; trigger alignment—whitespaces not in aligned output. | Medium (affects timings around whitespaces) |

### Bugs Causing Words Metadata (start, end, prob) to Disappear After Save

Metadata loss ties closely to whitespace bugs, as skipped/mismatched tokens don't carry over or persist timings/probabilities. Non-whitespace tokens can also lose metadata if retokenization or carry-over fails.

| Bug Description | Code References | Why It Causes Metadata Loss | Reproduction Steps | Severity |
| --- | --- | --- | --- | --- |
| **Metadata not persisted for skipped whitespace tokens** | `_populate_transcript_words`: Skip if `word.strip() == ''`; metadata fields ignored for skips. | Skipped tokens aren't in `transcript_words`, so their `start_time`, `end_time`, `probability` aren't stored. On reload via `/words`, metadata is absent. Confirmed via code execution: metadata for '  ' and ' ' was not inserted. | Save whitespace token with `start=1.0, end=2.0`; reload—metadata gone. | High (total loss for whitespaces) |
| **Carry-over skips metadata for unmatched tokens (including whitespaces)** | `_carry_over_timings`: Matches via `str(prev_seq[j]['word'] or '') == t`; prev loaded from `transcript_words` (skips whitespaces). | If no match (e.g., new whitespace token, or retokenized words), metadata defaults to None/0.0. Prior whitespaces weren't in DB, so can't carry over. For Hebrew words with leading spaces (e.g., " נדב" in example), if treated as whitespace-prefixed, mismatch could skip. | Save v1 with whitespace metadata; edit to v2—metadata not carried if skipped. | High (compounds over versions) |
| **Retokenization resets metadata to None** | `_ensure_words_match_text`: Returns `_tokenize_text_to_words(text)`, which sets `start/end/prob=None`. | If triggered, all metadata is discarded and not recovered until carry-over (which may fail for mismatches). In example JSON, if `text` mismatches due to spaces, timings/probs from segments/words are lost. | Cause mismatch; save—reload shows None for all metadata until realignment. | Medium (only on mismatch) |
| **Normalization overwrites invalid metadata without preserving whitespaces** | `_normalize_end_times`: Derives ends from next starts, but skips whitespaces (no rows). | If whitespace had metadata bounding other tokens, it's ignored. Last token in segment gets arbitrary `min_dur` if no next. For skipped whitespaces, no normalization at all. | Save with invalid end on token before whitespace; reload—metadata adjusted without whitespace influence. | Low (indirect) |

### Other Bugs/Issues

- **Unicode/RTL Handling (e.g., Hebrew in Example JSON)**: `_tokenize_text_to_words` uses `split()`, which works for Hebrew spaces but loses directionality-aware whitespaces. Difflib in `_diff` treats RTL chars as sequences, but diffs may render poorly in UI if not handled.
- **Potential Crash in JSON Handling**: `orjson.dumps(words)` assumes serializable; if words have non-JSON types (e.g., NaN prob), fails silently or aborts. Use try-except.
- **Alignment Skips Whitespaces in Mapping**: `_map_aligned_to_updates`: `new_seq = [(i, _norm(t)) for ... if _norm(t) != '']` (_norm=strip()) skips whitespaces, so no timing updates for them.
- **No Validation for Negative/NaN Metadata**: `_validate_and_sanitize_words` coerces to float but allows negative starts/ends or NaN probs, leading to invalid DB data.
- **Race Condition in Saves**: No transaction around conflict check and insert in `/save`; concurrent saves could duplicate versions.

These bugs were identified via static analysis and confirmed with code execution tool simulations (e.g., DB inserts and function tests). For fixes and testing, refer to prior response.